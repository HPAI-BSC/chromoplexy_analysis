{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Generation\n",
    "\n",
    "This code generates a dataset with the next features and saves it as a csv: \n",
    "\n",
    "This dataset has the next features\n",
    "* chr_1, chr_2, ...,chr_X, chr_Y: The number of breaks of the chromosome on this patient. \n",
    "* DUP, DEL, TRA, h2hINV, t2tINV: The number of the breaks of this kind. \n",
    "* One feature for each of the possible translocation with the cuantity of this translocations on this patient. \n",
    "* DEL_1, ... DEL_X, DEL_Y: The number of deletions on the target chromosome. \n",
    "* DUP_1, ... DUP_X, DUP_Y: The number of duplications on the target chromosome. \n",
    "* Number of breaks: The total number of breaks of the patient. \n",
    "* Connected components: The number of connected components of the translocation graph.\n",
    "* Connected components max size: The maximum size of the connected components of the translocation graph.\n",
    "* The metadata features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(1, '../../src')\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.dtype size changed\")\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "\n",
    "from step1.graph_builder import generateTRAGraph\n",
    "\n",
    "from datetime import timedelta\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data paths:\n",
    "DATA_PATH = '../../data_chromosome'\n",
    "OUTPUT_PATH = DATA_PATH + '/datasets'\n",
    "try: os.mkdir(DATA_PATH)\n",
    "except: pass\n",
    "try: os.mkdir(OUTPUT_PATH)\n",
    "except: pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_dataset(patients, data_path, output_path, name='classification_dataset.csv'):\n",
    "    \"\"\"\n",
    "    This function generates a dataset from the patient names on \"patients\" and saves it in \"output path\"\n",
    "     as a csv with the name \"name\". \n",
    "    \n",
    "    This dataset has the next features\n",
    "        * chr_1, chr_2, ...,chr_X, chr_Y: The number of breaks of the chromosome on this patient. \n",
    "        * DUP, DEL, TRA, h2hINV, t2tINV: The number of the breaks of this kind. \n",
    "        * One feature for each of the possible translocation with the cuantity of this translocations on this patient. \n",
    "        * DEL_1, ... DEL_X, DEL_Y: The number of deletions on the target chromosome. \n",
    "        * DUP_1, ... DUP_X, DUP_Y: The number of duplications on the target chromosome. \n",
    "        * Number of breaks: The total number of breaks of the patient. \n",
    "        * Connected components: The number of connected components of the translocation graph.\n",
    "        * Connected components max size: The maximum size of the connected components of the translocation graph.\n",
    "        * The metadata features\n",
    "    \"\"\"\n",
    "    print 'Generating csv..'\n",
    "    metadata = pd.read_csv(data_path + '/raw_original_data/metadatos_v2.0.csv')\n",
    "    metadata = metadata.set_index('sampleID')\n",
    "    # Remove the patients that doesn't have metadata\n",
    "    l = len(patients)\n",
    "    patients = [p for p in patients if p in list(metadata.index)]\n",
    "    print 'There are ', l-len(patients) , 'patients that do not appear in metadata'\n",
    "    chromosomes = ['1', '2', '3', '4', '5', '6', '7', '8', '9', '10', '11', '12', '13', '14', '15', '16', '17', '18',\n",
    "                   '19', '20', '21', '22', 'X', 'Y']\n",
    "    svclass = ['DUP', 'DEL', 'TRA', 'h2hINV', 't2tINV']\n",
    "    graph_columns = ['(' + chromosomes[i] + ',' + chromosomes[j] + ')' for i in range(len(chromosomes))\n",
    "                                     for j in range(len(chromosomes)) if i < j]\n",
    "\n",
    "    all_columns = np.append(metadata.columns, graph_columns).flatten()\n",
    "\n",
    "    # initialize the dataset and append the metadata to it\n",
    "    dataset = pd.DataFrame(columns=all_columns)\n",
    "    dataset = pd.concat([dataset, metadata])\n",
    "    # initialize the graph related columns\n",
    "    # dataset.loc[:, graph_columns] = 0\n",
    "\n",
    "    i = 0\n",
    "    for patient in metadata.index:\n",
    "        g, edge_list, matrix = generateTRAGraph(patient=patient, data_path=data_path, output_path='', connected_only=True, plot_graph=False)\n",
    "        dataset.loc[patient, 'connected_components'] = len(list(nx.connected_component_subgraphs(g)))\n",
    "        # the max of the number of vertex of the connected components of the graph\n",
    "        if len(list(nx.connected_component_subgraphs(g))) > 0:\n",
    "            dataset.loc[patient, 'connected_components_max_size'] = np.max(\n",
    "                [len(list(component.nodes())) for component in nx.connected_component_subgraphs(g)])\n",
    "        else:\n",
    "            dataset.loc[patient, 'connected_components_max_size'] = 0\n",
    "        for edge in edge_list:\n",
    "            edge = edge.split(' ')\n",
    "            if edge[0]  in ['X', 'Y'] and edge[1] in ['X','Y']:\n",
    "                edge_column = '(' + 'X' + ',' + 'Y' + ')'\n",
    "            elif edge[0] in ['X', 'Y']:\n",
    "                edge_column = '(' + edge[1] + ',' + edge[0] + ')'\n",
    "            elif edge[1] in ['X', 'Y']:\n",
    "                edge_column = '(' + edge[0] + ',' + edge[1] + ')'\n",
    "            elif int(edge[0]) < int(edge[1]):\n",
    "                edge_column = '(' + edge[0] + ',' + edge[1] + ')'\n",
    "            else:\n",
    "                edge_column = '(' + edge[1] + ',' + edge[0] + ')'\n",
    "            edge_weight = int(edge[2])\n",
    "            # print edge, edge_column, edge_weight\n",
    "            dataset.loc[patient, edge_column] = edge_weight\n",
    "        i += 1\n",
    "    # initialize the chromosome columns at 0\n",
    "    for chrom in chromosomes:\n",
    "        dataset['chr_' + str(chrom)] = 0\n",
    "        dataset['DEL_' + str(chrom)] = 0\n",
    "        dataset['DUP_' + str(chrom)] = 0\n",
    "\n",
    "    # initialize the svclass columns at 0\n",
    "    for cls in svclass:\n",
    "        dataset[cls] = 0\n",
    "\n",
    "    # for all patients on the dataset load its breaks and extract their data\n",
    "    for patient in dataset.index:\n",
    "        patient_path = data_path + '/raw_original_data/allfiles/' + patient + '.vcf.tsv'\n",
    "        patient_breaks = pd.read_csv(patient_path, sep='\\t', index_col=None)\n",
    "\n",
    "        # load the chromosomes as strings\n",
    "        patient_breaks['chrom2'] = patient_breaks['chrom2'].map(str)\n",
    "        # generate a crosstab of the svclass with the chromosomes\n",
    "        ct = pd.crosstab(patient_breaks['chrom2'], patient_breaks['svclass'])\n",
    "        ct.index = ct.index.map(str)\n",
    "        # print(ct)\n",
    "        for chrom in chromosomes:\n",
    "            if chrom in ct.index:\n",
    "                if 'DEL' in ct.columns:\n",
    "                    dataset.loc[patient, ['DEL_' + str(chrom)]] = ct.loc[chrom, ['DEL']].values[0]\n",
    "                if 'DUP' in ct.columns:\n",
    "                    dataset.loc[patient, ['DUP_' + str(chrom)]] = ct.loc[chrom, ['DUP']].values[0]\n",
    "\n",
    "\n",
    "        number_of_breaks = len(patient_breaks)\n",
    "        dataset.loc[patient, 'number_of_breaks'] = number_of_breaks\n",
    "\n",
    "        # I count how many times appears on the breaks each of the chromosomes.\n",
    "        contained_chromosomes = patient_breaks[['#chrom1', 'chrom2']].apply(pd.Series.value_counts)\n",
    "        contained_chromosomes = contained_chromosomes.fillna(0)\n",
    "        contained_chromosomes[['#chrom1', 'chrom2']] = contained_chromosomes[['#chrom1', 'chrom2']].astype(int)\n",
    "        contained_chromosomes['chromosome'] = contained_chromosomes.index\n",
    "        contained_chromosomes['count'] = contained_chromosomes['#chrom1'] + contained_chromosomes['chrom2']\n",
    "        # Then saves it on the chromosome feature.\n",
    "        for chrom in contained_chromosomes.index:\n",
    "            dataset.loc[patient, ['chr_' + str(chrom)]] = contained_chromosomes.loc[chrom, ['count']].values[0]\n",
    "\n",
    "        # Counts how many breaks of each class there are on the breaks and saves it.\n",
    "        count_svclass = patient_breaks[['svclass', ]].apply(pd.Series.value_counts)\n",
    "        for svclass in count_svclass.index:\n",
    "            dataset.loc[patient, [svclass]] = count_svclass.loc[svclass, ['svclass']].values[0]\n",
    "    # fill with zeros the translocation graph edges not filled on the edge part.\n",
    "    dataset.loc[:, dataset.columns != 'donor_age_at_diagnosis'] = dataset.loc[:, dataset.columns != 'donor_age_at_diagnosis'].fillna(0)\n",
    "    print 'Saved on the path: ',output_path + '/' + name\n",
    "    dataset.to_csv(output_path +'/'+ name)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating csv..\n",
      "There are  13 patients that do not appear in metadata\n",
      "('saved on the path: ', '../../data_chromosome/datasets/dataset__chrom.csv')\n",
      "Total time: 0:04:32.061677\n"
     ]
    }
   ],
   "source": [
    "data_path = DATA_PATH + '/raw_original_data/allfiles'\n",
    "all_patients = os.listdir(data_path)\n",
    "all_patients = [p.replace('.vcf.tsv','') for p in all_patients]\n",
    "name = 'dataset_' + 'chrom.csv'\n",
    "init = time.time()\n",
    "dataset = generate_dataset(patients=all_patients, data_path=DATA_PATH, output_path=OUTPUT_PATH, name=name)\n",
    "print 'Total time:', timedelta(seconds=time.time() - init)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>(1,10)</th>\n",
       "      <th>(1,11)</th>\n",
       "      <th>(1,12)</th>\n",
       "      <th>(1,13)</th>\n",
       "      <th>(1,14)</th>\n",
       "      <th>(1,15)</th>\n",
       "      <th>(1,16)</th>\n",
       "      <th>(1,17)</th>\n",
       "      <th>(1,18)</th>\n",
       "      <th>(1,19)</th>\n",
       "      <th>...</th>\n",
       "      <th>DUP_X</th>\n",
       "      <th>chr_Y</th>\n",
       "      <th>DEL_Y</th>\n",
       "      <th>DUP_Y</th>\n",
       "      <th>DUP</th>\n",
       "      <th>DEL</th>\n",
       "      <th>TRA</th>\n",
       "      <th>h2hINV</th>\n",
       "      <th>t2tINV</th>\n",
       "      <th>number_of_breaks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>f393ba16-9361-5df4-e040-11ac0d4844e8</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f393baf9-2710-9203-e040-11ac0d484504</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>166</td>\n",
       "      <td>47</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>277.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f393bafd-1baa-e5f4-e040-11ac0d48450b</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39</td>\n",
       "      <td>116</td>\n",
       "      <td>36</td>\n",
       "      <td>30</td>\n",
       "      <td>28</td>\n",
       "      <td>249.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f393bafe-c99f-3725-e040-11ac0d484514</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "      <td>45</td>\n",
       "      <td>34</td>\n",
       "      <td>18</td>\n",
       "      <td>16</td>\n",
       "      <td>175.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>f393bafe-7503-5c45-e040-11ac0d484511</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>91</td>\n",
       "      <td>42</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "      <td>179.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 362 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      (1,10)  (1,11)  (1,12)  (1,13)  (1,14)  \\\n",
       "f393ba16-9361-5df4-e040-11ac0d4844e8       0       0       0       0       0   \n",
       "f393baf9-2710-9203-e040-11ac0d484504       1       2       2       0       0   \n",
       "f393bafd-1baa-e5f4-e040-11ac0d48450b       0       0       0       0       0   \n",
       "f393bafe-c99f-3725-e040-11ac0d484514       0       0       0       0       0   \n",
       "f393bafe-7503-5c45-e040-11ac0d484511       0       0       1       0       1   \n",
       "\n",
       "                                      (1,15)  (1,16)  (1,17)  (1,18)  (1,19)  \\\n",
       "f393ba16-9361-5df4-e040-11ac0d4844e8       0       0       0       0       0   \n",
       "f393baf9-2710-9203-e040-11ac0d484504       2       0       2       0       0   \n",
       "f393bafd-1baa-e5f4-e040-11ac0d48450b       0       0       0       0       0   \n",
       "f393bafe-c99f-3725-e040-11ac0d484514       0       0       0       0       1   \n",
       "f393bafe-7503-5c45-e040-11ac0d484511       0       2       0       0       0   \n",
       "\n",
       "                                            ...         DUP_X  chr_Y  DEL_Y  \\\n",
       "f393ba16-9361-5df4-e040-11ac0d4844e8        ...             0      0      0   \n",
       "f393baf9-2710-9203-e040-11ac0d484504        ...             3      0      0   \n",
       "f393bafd-1baa-e5f4-e040-11ac0d48450b        ...             2      0      0   \n",
       "f393bafe-c99f-3725-e040-11ac0d484514        ...             2      0      0   \n",
       "f393bafe-7503-5c45-e040-11ac0d484511        ...             3      0      0   \n",
       "\n",
       "                                      DUP_Y  DUP  DEL  TRA  h2hINV  t2tINV  \\\n",
       "f393ba16-9361-5df4-e040-11ac0d4844e8      0    5   10    6       8       4   \n",
       "f393baf9-2710-9203-e040-11ac0d484504      0  166   47   47       9       8   \n",
       "f393bafd-1baa-e5f4-e040-11ac0d48450b      0   39  116   36      30      28   \n",
       "f393bafe-c99f-3725-e040-11ac0d484514      0   62   45   34      18      16   \n",
       "f393bafe-7503-5c45-e040-11ac0d484511      0   21   91   42      13      12   \n",
       "\n",
       "                                      number_of_breaks  \n",
       "f393ba16-9361-5df4-e040-11ac0d4844e8              33.0  \n",
       "f393baf9-2710-9203-e040-11ac0d484504             277.0  \n",
       "f393bafd-1baa-e5f4-e040-11ac0d48450b             249.0  \n",
       "f393bafe-c99f-3725-e040-11ac0d484514             175.0  \n",
       "f393bafe-7503-5c45-e040-11ac0d484511             179.0  \n",
       "\n",
       "[5 rows x 362 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromoplexy_analysis",
   "language": "python",
   "name": "chromoplexy_analysis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
